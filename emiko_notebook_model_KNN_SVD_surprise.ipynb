{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "#from sklearn import cross_validation as cv\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "from surprise.prediction_algorithms import knns\n",
    "from surprise.similarities import cosine, msd, pearson\n",
    "from surprise import accuracy\n",
    "from surprise import Reader, Dataset\n",
    "from surprise.model_selection import train_test_split, cross_validate, GridSearchCV\n",
    "from surprise.prediction_algorithms import KNNWithMeans, KNNBasic, KNNBaseline, SVD, NMF\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read master data\n",
    "master = pd.read_csv('Data/master.csv')\n",
    "\n",
    "# Drop unnecessary columns\n",
    "master_1 = master.loc[:, ['movieId', 'userId', 'rating']]\n",
    "master_1.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaborative filtering \n",
    "\n",
    "1. KNN with scipy sparse matrix \n",
    "2. KNN-KNNBasic, KNNMeans, KNNBasline (with surprise)\n",
    "3. Matrix Factorization- SVD (with surpise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Memory-Based Methods (Neighborhood-Based)\n",
    "## 1. KNN with scipy sparse matrix \n",
    "Because we have fewer items than users, we calculate item-item similarity. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Movie-user matrices (rows=movieId, columns=userId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>userId</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>601</th>\n",
       "      <th>602</th>\n",
       "      <th>603</th>\n",
       "      <th>604</th>\n",
       "      <th>605</th>\n",
       "      <th>606</th>\n",
       "      <th>607</th>\n",
       "      <th>608</th>\n",
       "      <th>609</th>\n",
       "      <th>610</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>movieId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 610 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "userId   1    2    3    4    5    6    7    8    9    10   ...  601  602  603  \\\n",
       "movieId                                                    ...                  \n",
       "1        4.0  0.0  0.0  0.0  4.0  0.0  4.5  0.0  0.0  0.0  ...  4.0  0.0  4.0   \n",
       "2        0.0  0.0  0.0  0.0  0.0  4.0  0.0  4.0  0.0  0.0  ...  0.0  4.0  0.0   \n",
       "3        4.0  0.0  0.0  0.0  0.0  5.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "4        0.0  0.0  0.0  0.0  0.0  3.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "5        0.0  0.0  0.0  0.0  0.0  5.0  0.0  0.0  0.0  0.0  ...  0.0  0.0  0.0   \n",
       "\n",
       "userId   604  605  606  607  608  609  610  \n",
       "movieId                                     \n",
       "1        3.0  4.0  2.5  4.0  2.5  3.0  5.0  \n",
       "2        5.0  3.5  0.0  0.0  2.0  0.0  0.0  \n",
       "3        0.0  0.0  0.0  0.0  2.0  0.0  0.0  \n",
       "4        0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "5        3.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 610 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pivot and create movie-user matrix and fill missing observations with 0s\n",
    "movie_to_user_df = master_1.pivot(\n",
    "    index='movieId',\n",
    "     columns='userId',\n",
    "      values='rating').fillna(0)\n",
    "\n",
    "movie_to_user_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9724, 610)\n"
     ]
    }
   ],
   "source": [
    "# transform matrix to scipy sparse matrix\n",
    "\n",
    "movie_to_user_sparse_df = csr_matrix(movie_to_user_df.values)\n",
    "movie_to_user_sparse_df\n",
    "\n",
    "# Check the shape\n",
    "print(movie_to_user_sparse_df.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Check sparsity of the movie-user matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is about 98.30% of ratings in our data is missing\n"
     ]
    }
   ],
   "source": [
    "# calcuate total number of entries in the movie-user matrix\n",
    "num_entries = movie_to_user_df.shape[0] * movie_to_user_df.shape[1]\n",
    "# calculate total number of entries with zero values\n",
    "num_zeros = (movie_to_user_df==0).sum(axis=1).sum()\n",
    "# calculate ratio of number of zeros to number of entries\n",
    "ratio_zeros = num_zeros / num_entries\n",
    "print('There is about {:.2%} of ratings in our data is missing'.format(ratio_zeros))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insights: The majority of entries is zero. With too many zeros, the distance between similar items in KNN model will be very large."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting K-Nearest Neighbours model to the scipy sparse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='brute', metric='cosine', n_jobs=-1, n_neighbors=20)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fiting the model \n",
    "\n",
    "knn_model = NearestNeighbors(metric='cosine', algorithm='brute', n_neighbors=20, n_jobs=-1)\n",
    "\n",
    "knn_model.fit(movie_to_user_sparse_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the trained model to make movie recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_list = list(movie_to_user_df.index)\n",
    "# Creating a dictionary with movie name as key and its index from the list as value \n",
    "movie_dict = {movie : index for index, movie in enumerate(movies_list)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function to find top n similar movies of the given movie title. \n",
    "\n",
    "def get_similar_movies(title, n = 5):\n",
    "    ## get movieId from title\n",
    "    movie_id= master.loc[master.title==title, 'movieId'][0]\n",
    "    ## input to this function is the movie and number of top similar movies you want.\n",
    "    index = movie_dict[movie_id]\n",
    "    knn_input = np.asarray([movie_to_user_df.values[index]])\n",
    "    n = min(len(movies_list)-1,n)\n",
    "    distances, indices = knn_model.kneighbors(knn_input, n_neighbors=n+1)\n",
    "    print(\"Top\",n,\"movies which are very much similar to the Movie-\",title, \"are: \")\n",
    "    print(\" \")\n",
    "    for i in range(1,len(distances[0])):\n",
    "        print(master.loc[master.movieId==movies_list[indices[0][i]], 'title'][:1])\n",
    "        #print(movies_list[indices[0][i]], master.loc[master.movieId==movies_list[indices[0][i]], 'title'][:1])\n",
    "        \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 movies which are very much similar to the Movie- Toy Story (1995) are: \n",
      " \n",
      "52421    Toy Story 2 (1999)\n",
      "Name: title, dtype: object\n",
      "13387    Jurassic Park (1993)\n",
      "Name: title, dtype: object\n",
      "19177    Independence Day (a.k.a. ID4) (1996)\n",
      "Name: title, dtype: object\n",
      "6905    Star Wars: Episode IV - A New Hope (1977)\n",
      "Name: title, dtype: object\n",
      "10305    Forrest Gump (1994)\n",
      "Name: title, dtype: object\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "get_similar_movies('Toy Story (1995)',5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. KNN with surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read new_df as Surprise dataset \n",
    "# specify the range of rating 0.5-5 (defalt setting is 1-5)\n",
    "reader = Reader(rating_scale =(0.5, 5) ) \n",
    "df = Dataset.load_from_df(master_1,reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users:  9724 \n",
      "\n",
      "Number of items:  610 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# report how many users and items we have in our dataset\n",
    "dataset = df.build_full_trainset()\n",
    "\n",
    "print('Number of users: ', dataset.n_users, '\\n')\n",
    "print('Number of items: ', dataset.n_items, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min rating: 0.5\n",
      "Max rating: 5.0\n"
     ]
    }
   ],
   "source": [
    "# the range of ratings \n",
    "print('Min rating:', master_1.rating.min())\n",
    "print('Max rating:', master_1.rating.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train test split with test size of 20% \n",
    "\n",
    "trainset, testset = train_test_split(df, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNNBasic\n",
    "A basic collaborative filtering algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two similarity options \n",
    "\n",
    "sim_cos = {'name':'cosine', 'user_based':False}\n",
    "sim_pearson = {'name':'pearson', 'user_based':False}\n",
    "\n",
    "sim_options = [sim_cos, sim_pearson]\n",
    "\n",
    "# Ks \n",
    "list_of_ks = [10,20,40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating sim_option = cosine and k = 10:\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE 0.994164707209045\n",
      "Calculating sim_option = cosine and k = 20:\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE 0.9821544120129753\n",
      "Calculating sim_option = cosine and k = 40:\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE 0.978840977526117\n",
      "Calculating sim_option = pearson and k = 10:\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE 0.999416882962629\n",
      "Calculating sim_option = pearson and k = 20:\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE 0.9881620825944339\n",
      "Calculating sim_option = pearson and k = 40:\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE 0.9855646764180745\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter Tuning\n",
    "# KNNBasic \n",
    "for sim in sim_options:\n",
    "\n",
    "    for k in list_of_ks:\n",
    "        \n",
    "        print(\n",
    "            'Calculating sim_option = ' + str(sim['name']) + \\\n",
    "            ' and k = ' + str(k) + ':' )        \n",
    "        algo = KNNBasic(k = k, sim_options = sim)\n",
    "        results = cross_validate(algo, df, measures=['RMSE'], cv=3, return_train_measures=True);\n",
    "        print('RMSE', np.mean(results['test_rmse']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insights: For KNN Basic, pick {sim_option = cosine and k = 40} , RMSE 0.9808902092915393"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validating with KNNBasic, item-based approach \n",
    "\n",
    "sim_cos = {'name':'cosine', 'user_based':False}\n",
    "\n",
    "basic = KNNBasic(sim_options=sim_cos)\n",
    "cv_knn_basic = cross_validate(basic, trainset, measures=['RMSE'], cv=3, n_jobs = -1)\n",
    "\n",
    "# n_jobs =-1 to ensures that all of the cores will be used to process fitting and evaluating. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('test_rmse', array([0.98314383, 0.98263915, 0.97586189]))\n",
      "('fit_time', (0.1603069305419922, 0.15911293029785156, 0.15041875839233398))\n",
      "('test_time', (1.33148193359375, 1.3358078002929688, 1.3139100074768066))\n",
      "-----------------------\n",
      "0.980548287552845\n"
     ]
    }
   ],
   "source": [
    "# print out the average RMSE score for the test set\n",
    "for i in cv_knn_basic.items():\n",
    "    print(i)\n",
    "print('-----------------------')\n",
    "print(np.mean(cv_knn_basic['test_rmse']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNNMean\n",
    "This is the same thing as the basic KNN model, except it takes into account the mean rating of each item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating sim_option = cosine and k = 10:\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE 0.9208576776199479\n",
      "Calculating sim_option = cosine and k = 20:\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE 0.9106196853698317\n",
      "Calculating sim_option = cosine and k = 40:\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE 0.9090380269766835\n",
      "Calculating sim_option = pearson and k = 10:\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE 0.9203209296654903\n",
      "Calculating sim_option = pearson and k = 20:\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE 0.912464431062943\n",
      "Calculating sim_option = pearson and k = 40:\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE 0.9079785175984204\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter Tuning\n",
    "# KNNMeans \n",
    "for sim in sim_options:\n",
    "\n",
    "    for k in list_of_ks:\n",
    "        \n",
    "        print(\n",
    "            'Calculating sim_option = ' + str(sim['name']) + \\\n",
    "            ' and k = ' + str(k) + ':' )        \n",
    "        algo = KNNWithMeans(k = k, sim_options = sim)\n",
    "        results = cross_validate(algo, df, measures=['RMSE'], cv=3, return_train_measures=True);\n",
    "        print('RMSE', np.mean(results['test_rmse']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insights: For KNN Means, pick {sim_option = pearson and k = 40} , RMSE 0.9079785175984204"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validating with KNNMean\n",
    "mean = KNNWithMeans(sim_options=sim_cos)\n",
    "cv_knn_mean = cross_validate(mean, df, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('test_rmse', array([0.90727953, 0.89911284, 0.909075  , 0.89607843, 0.90052929]))\n",
      "('test_mae', array([0.6935493 , 0.68596303, 0.69642293, 0.68642909, 0.6873128 ]))\n",
      "('fit_time', (0.220444917678833, 0.2231001853942871, 0.23791122436523438, 0.21805715560913086, 0.21230316162109375))\n",
      "('test_time', (1.1647169589996338, 1.1703667640686035, 1.1610219478607178, 1.1665871143341064, 1.1365859508514404))\n",
      "-----------------------\n",
      "0.9024150170275282\n"
     ]
    }
   ],
   "source": [
    "# print out the average RMSE score for the test set\n",
    "for i in cv_knn_mean.items():\n",
    "    print(i)\n",
    "print('-----------------------')\n",
    "print(np.mean(cv_knn_mean['test_rmse']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNNBaseline\n",
    "It takes into account a baseline rating. It adds biases for items and users. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating sim_option = cosine and k = 10:\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE 0.8952920093005599\n",
      "Calculating sim_option = cosine and k = 20:\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE 0.8883825238225258\n",
      "Calculating sim_option = cosine and k = 40:\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the cosine similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE 0.8868368800819563\n",
      "Calculating sim_option = pearson and k = 10:\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE 0.8986413338895433\n",
      "Calculating sim_option = pearson and k = 20:\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE 0.890937921555708\n",
      "Calculating sim_option = pearson and k = 40:\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Estimating biases using als...\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE 0.8889123591532005\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter Tuning\n",
    "# KNNBaseline \n",
    "for sim in sim_options:\n",
    "\n",
    "    for k in list_of_ks:\n",
    "        \n",
    "        print(\n",
    "            'Calculating sim_option = ' + str(sim['name']) + \\\n",
    "            ' and k = ' + str(k) + ':' )        \n",
    "        algo = KNNBaseline(k = k, sim_options = sim)\n",
    "        results = cross_validate(algo, df, measures=['RMSE'], cv=3, return_train_measures=True);\n",
    "        print('RMSE', np.mean(results['test_rmse']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Insights: For KNN Baseline, pick {sim_option = cosine and k = 40} , RMSE 0.8868368800819563"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validating with KNNBaseline\n",
    "baseline = KNNBaseline(sim_options=sim_cos)\n",
    "cv_knn_baseline = cross_validate(baseline, df, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('test_rmse', array([0.88192946, 0.87554556, 0.8668803 , 0.885553  , 0.88569512]))\n",
      "('test_mae', array([0.67470494, 0.67041945, 0.66629289, 0.67539273, 0.67660623]))\n",
      "('fit_time', (0.27367234230041504, 0.27748608589172363, 0.27275800704956055, 0.24278593063354492, 0.25119614601135254))\n",
      "('test_time', (1.4932341575622559, 1.4593956470489502, 1.4546098709106445, 1.4698169231414795, 1.439692735671997))\n",
      "-----------------------\n",
      "0.879120687193384\n"
     ]
    }
   ],
   "source": [
    "# print out the average score for the test set\n",
    "for i in cv_knn_baseline.items():\n",
    "    print(i)\n",
    "print('-----------------------')\n",
    "print(np.mean(cv_knn_baseline['test_rmse']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model-Based Methods \n",
    "## 3. Matrix Factorization with surprise\n",
    "### SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:    2.7s\n",
      "[Parallel(n_jobs=-1)]: Done 112 tasks      | elapsed:   23.0s\n",
      "[Parallel(n_jobs=-1)]: Done 162 out of 162 | elapsed:   42.8s finished\n"
     ]
    }
   ],
   "source": [
    "## Perform a gridsearch with SVD\n",
    "\n",
    "param_grid = {'n_factors':[20, 50, 100],'n_epochs': [5, 10, 15], 'lr_all': [0.002, 0.005, 0.01],\n",
    "               'reg_all': [0.04, 0.06]}\n",
    "gs_model = GridSearchCV(SVD, param_grid, cv=3, n_jobs = -1, joblib_verbose=3)\n",
    "gs_model.fit(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8776272643241537\n",
      "{'n_factors': 100, 'n_epochs': 15, 'lr_all': 0.01, 'reg_all': 0.06}\n"
     ]
    }
   ],
   "source": [
    "# print out optimal parameters for SVD after GridSearch\n",
    "print(gs_model.best_score['rmse'])\n",
    "print(gs_model.best_params['rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVD with best params \n",
    "svd = SVD(n_factors=100, n_epochs=15, lr_all=0.01, reg_all=0.06)\n",
    "cv_svd = cross_validate(svd, df, cv=3, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('test_rmse', array([0.87349157, 0.87693559, 0.88158069]))\n",
      "('test_mae', array([0.67147149, 0.67725865, 0.67718558]))\n",
      "('fit_time', (2.3285319805145264, 2.3774940967559814, 2.8599600791931152))\n",
      "('test_time', (0.1505889892578125, 0.15070605278015137, 0.1367800235748291))\n",
      "-----------------------\n",
      "0.8773359498086899\n"
     ]
    }
   ],
   "source": [
    "for i in cv_svd.items():\n",
    "    print(i)\n",
    "print('-----------------------')\n",
    "print(np.mean(cv_svd['test_rmse']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making Recommendations\n",
    "### Making simple predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated rating for user=2 item=4:  3.87\n"
     ]
    }
   ],
   "source": [
    "# make a prediction for an individual user and item using the SVD model above\n",
    "model = SVD(n_factors=100, n_epochs=15, lr_all=0.01, reg_all=0.06)\n",
    "model.fit(trainset)\n",
    "\n",
    "# a prediction for user 50 and item 4 \n",
    "pred = model.predict(uid = 5, iid=1)\n",
    "score = pred.est\n",
    "print('Estimated rating for user=2 item=4: ', round(score, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make recommendations to an existing user (uid =50)\n",
    "\n",
    "### reference https://blog.cambridgespark.com/tutorial-practical-introduction-to-recommender-systems-dbe22848392b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the movie ids that user 50 didn’t rate \n",
    "\n",
    "# get a list of all movie titles \n",
    "iids = master['title'].unique()\n",
    "# Get a list of movie ids that uid 50 has rated \n",
    "iid50 = master.loc[master['userId']==50, 'title']\n",
    "# Remove the iids that uid50 has rated from the lisf of iids\n",
    "iids_to_pred = np.setdiff1d(iids, iid50)  # setdiff1d = Find the set difference of two arrays.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction(uid=50, iid=\"'71 (2014)\", r_ui=4.0, est=4.201787625891698, details={'was_impossible': False})"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict the score of each of the movie ids that user 50 didn’t rate, and find the best one.\n",
    "\n",
    "# create another dataset with the iids\n",
    "# arbitrarily set all the ratings of this test set to 4\n",
    "\n",
    "testset = [[50, iid, 4.] for iid in iids_to_pred]\n",
    "predictions = model.test(testset)\n",
    "predictions[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 item for user 50 is ['Fried Green Tomatoes (1991)'\n",
      " 'Friday the 13th Part VI: Jason Lives (1986)'\n",
      " 'Friday the 13th Part 3: 3D (1982)'\n",
      " 'Friday the 13th Part IV: The Final Chapter (1984)'\n",
      " 'À nous la liberté (Freedom for Us) (1931)']\n"
     ]
    }
   ],
   "source": [
    "# Predict the score of each of the movie ids that user 50 didn’t rate, and find the top one.\n",
    "\n",
    "pred_ratings = np.array([pred.est for pred in predictions])\n",
    "\n",
    "# Find the index of the max predicted rating \n",
    "#i_max = pred_ratings.argmax()\n",
    "\n",
    "# Use this to find the corresponding movie title to recommend \n",
    "#iid = iids_to_pred[i_max]\n",
    "\n",
    "#print('Top item for user 50 is {} with predicted rating {}'\n",
    "#      .format(iid, pred_ratings[i_max]))\n",
    "\n",
    "\n",
    "# Find the index of top 5 predicted ratings\n",
    "i_max_5 = pred_ratings.argpartition(-5)[-5:]\n",
    "\n",
    "iid_5 = iids_to_pred[i_max_5]\n",
    "\n",
    "print('Top 5 item for user 50 is {}'\n",
    "      .format(iid_5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
